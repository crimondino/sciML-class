{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQQyJRQPZo1v"
   },
   "source": [
    "# This is a simple notebook to use Logistic Regression model for the Ising model.\n",
    "\n",
    "It accompanies Chapter 5 of the book (4 of 5).\n",
    "\n",
    "Copyright: Viviana Acquaviva (2023); see also other data credits below.\n",
    "\n",
    "This notebook is modified by Gang Xu for PSI Scientific Machine Learning course. \n",
    "\n",
    "License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries <span style=\"color:blue\"> (no need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgmGOai2Zo1z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Lw_KF1lZo10",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate, train_test_split\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrBWd_LTZo17"
   },
   "source": [
    "## We now see an example from Mehta et al 2018:\n",
    "\n",
    "[\"A high-bias, low-variance introduction to Machine Learning for physicists\"](https://arxiv.org/abs/1803.08823).\n",
    "\n",
    "(Thank you to Pankaj Mehta and David Schwab)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NE4YN33cZo18"
   },
   "source": [
    "We are trying to use a logistic regression model to predict whether a material is in a ordered or disordered phase, based on its spin configuration. In an ordered phase, the spins are aligned. The representation is a 2D lattice so our features are the spin states of each element in the lattice. The physical model, known as Ising model, predicts that the transition depends on temperature and is smeared (for a finite-size lattice), around a critical temperature $T_c$.\n",
    "\n",
    "The training data is composed of 160,000 Monte Carlo simulations in a range of temperatures, and their labels.\n",
    "\n",
    "Possible applications of this formalism involve predicting the critical temperature for more complex systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data (Reading in the data might take a little while.) <span style=\"color:blue\"> (No need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6tAsGt1Zo18",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is gratefully borrowed with permission from the notebooks maintained by P. Mehta.\n",
    "\n",
    "######### LOAD DATA\n",
    "######### The data consists of 16*10000 samples taken in T=np.arange(0.25,4.0001,0.25):\n",
    "data_file_name = 'Ising2DFM_reSample_L40_T=All.pkl'\n",
    "######### The labels are obtained from the following file:\n",
    "label_file_name = 'Ising2DFM_reSample_L40_T=All_labels.pkl'\n",
    "\n",
    "\n",
    "############ DATA\n",
    "with open(data_file_name, 'rb') as pickle_file:\n",
    "#r=read b=binary pickle must be read in binary mode and needs to be open\n",
    "# with... as... will automatically close the file after opening it is safer\n",
    "    data = pickle.load(pickle_file) # pickle reads the file and returns the Python object (1D array, compressed bits) and store in data\n",
    "\n",
    "#### Decompress array and reshape for convenience\n",
    "data = np.unpackbits(data).reshape(-1, 1600)\n",
    "#data has byte (8bits) unpackbits unpack it into 8 bits return a bunch of 0 and 1s\n",
    "#-1: figure out how many rows there are, each row has 1600=40*40 bits The length of the lattice is 40\n",
    "data=data.astype('int')\n",
    "#now convert the datatype to integer\n",
    "\n",
    "#### map 0 state to -1 (Ising variable can take values +/-1)\n",
    "data[np.where(data==0)]=-1 \n",
    "# np.where(data==0) find all indices where data is 0\n",
    "\n",
    "###### READ LABELS (convention is 1 for ordered states and 0 for disordered states)\n",
    "with open(label_file_name, 'rb') as pickle_file:\n",
    "    labels = pickle.load(pickle_file) # pickle reads the file and returns the Python object (here just a 1D array with the binary labels)\n",
    "print(data.shape) # the shape of the features\n",
    "print(np.unique(labels)) # the unique labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49GjVjxuZo1-"
   },
   "source": [
    "### Visualize the data: We can take a look at the label distribution. <span style=\"color:blue\"> (no need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pJYfeJwZo1_",
    "outputId": "a30c568c-942d-4fd9-830d-8b678de6b8dc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(data.shape[0]),labels)\n",
    "#data.shape[0]=160000\n",
    "\n",
    "plt.xlabel('Example #')\n",
    "\n",
    "plt.ylabel('State');\n",
    "\n",
    "###labels: 1 = ordered or near-critical\n",
    "###labels: 0 = disordered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0xzyn3QZo1_"
   },
   "source": [
    "### Write one-line code to tell if data is balanced or imbalanced here <span style=\"color:blue\"> part a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17IHPojSZo1_",
    "outputId": "dd0cb71a-8ab2-45de-9187-2e971e2bd8a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#student write code here for part a)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuBU35B4Zo2A"
   },
   "source": [
    "### Visualize the spin configurations <span style=\"color:blue\"> (Play with which data you want to look at, remember the data is not ordered from low temp to high temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppDWhqS3Zo2A",
    "outputId": "f76a9f97-a5fd-4eba-f1bc-62129bfe785c"
   },
   "outputs": [],
   "source": [
    "#H/T: https://stackoverflow.com/questions/16834861/create-own-colormap-using-matplotlib-and-plot-color-scale\n",
    "\n",
    "cmap = matplotlib.colors.ListedColormap([\"aquamarine\",\"navy\"], name='from_list', N=None)\n",
    "#[\"aquamarine\",\"navy\"] list of color for each value\n",
    "#name='from_list' optional name for the color list\n",
    "#N=None  # optional number of entries (auto from list)\n",
    "plt.figure(figsize=(15,8))\n",
    "fig, axarr = plt.subplots(nrows=1, ncols=3)\n",
    "axarr[0].imshow(data[0].reshape(40,40), cmap = cmap) #first object has label \"1\"\n",
    "axarr[1].imshow(data[80000].reshape(40,40), cmap = cmap) #from documentation, this is critical-ish (between 60, and 90,000)\n",
    "axarr[2].imshow(data[100000].reshape(40,40), cmap = cmap) #disordered\n",
    "for i in range(3):\n",
    "    axarr[i].set_xticks([0,20,40]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrDo7UeBZo2A"
   },
   "source": [
    "### Let's pick a random selection (10%) to shuffle the data. <span style=\"color:blue\"> (No need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBh9eoKBZo2B"
   },
   "outputs": [],
   "source": [
    "np.random.seed(228) #this random seed is carefully chosen so that one example is very special in the future\n",
    "\n",
    "sel = np.random.choice(data.shape[0], data.shape[0]//10, replace = False)\n",
    "#np.random.choice(\n",
    " #   a,         # range or array of values to choose from\n",
    "  #  size,      # number of samples to pick\n",
    "   # replace=False  # without replacement â†’ no repeats\n",
    "#)\n",
    "seldata = data[sel,:] # for all indices, select all data\n",
    "sellabels = labels[sel]\n",
    "plt.scatter(np.arange(seldata.shape[0]),sellabels); #The random selection has the advantage of reshuffling the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taicNCHTZo2C"
   },
   "source": [
    "### And now time for the logistic regression model. <span style=\"color:blue\"> (No need to change, need a bit patience here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYE-PYODZo2C"
   },
   "outputs": [],
   "source": [
    "###This uses a numerical method to find the minimum of the loss function\n",
    "model = LogisticRegression(max_iter = 1000) \n",
    "###Takes up to 3 minutes\n",
    "###We can use cross validation\n",
    "results = cross_validate(model, seldata, sellabels, \n",
    "                         cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score = True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What hyperparamters do we have to tune?<span style=\"color:blue\"> (No need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()\n",
    "#C inverse of regularization strength #all weights for classes are equal #dual false if samples>features.\n",
    "#usually we want an intercept scaling is only used for a different solver\n",
    "#l1ratio is used for other penalty #max_iter higher helps convergence #multi-class is auto#n_jobs use 1 core\n",
    "#l2 regularization type #random state can be picked to reproduce result \n",
    "#lbfgs is an optimalization algorithm #tol small means more precise, slower\n",
    "#verbose 0 means no progress print warm_start will reuse the previous solution as starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Vi0wSNaZo2F"
   },
   "source": [
    "### Write a code to optimize the regularization parameter C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMWzq8l-Zo2F",
    "outputId": "c704ce7e-7f6e-4545-c47c-b19e7a980325"
   },
   "outputs": [],
   "source": [
    "###Note that our data is already very regular (feature values are-1/1, so we are not doing any scaling).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7utkqo_Zo2G"
   },
   "source": [
    "### Here we generate the odds/probabilities in addition to labels in order to check predictions. <span style=\"color:blue\"> (No need to change)\n",
    "\n",
    "For those classifiers that are solving a regression problem under the hood, there is the handy \"predict_proba\" method. The output of predict_proba gives the probability to belong to disordered (label 0) or ordered (label 1) phase. The simple classifier output is the class with p > 0.5. We can look at this to convince ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUkJl1JSZo2H"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1.0, max_iter=1000)\n",
    "\n",
    "ypred = cross_val_predict(model, seldata, sellabels, \\\n",
    "                               cv = KFold(n_splits=5, shuffle=True, random_state=10))\n",
    "\n",
    "ypred_prob = cross_val_predict(model, seldata, sellabels, \\\n",
    "                               cv = KFold(n_splits=5, shuffle=True, random_state=10), method = 'predict_proba')\n",
    "print(np.column_stack([ypred_prob, ypred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjLRxlWoZo2H"
   },
   "source": [
    "### We can plot a few examples to see how our classifier is doing. <span style=\"color:blue\"> (No need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDPNCNxSZo2I",
    "outputId": "362c3603-2c27-4dfa-c651-80b8439b972c"
   },
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(nrows=1, ncols=12, figsize=(20,5))\n",
    "for i in range(12):\n",
    "    axarr[i].imshow(seldata[i].reshape(40,40), cmap = cmap) \n",
    "    axarr[i].set_xlabel('True label:'+str(sellabels[i])+'\\n'+'Pred label:'+str(ypred[i]))\n",
    "    axarr[i].set_yticks([])\n",
    "    axarr[i].set_xticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnHvxm_JZo2I"
   },
   "source": [
    "### Take a look at the corresponding probabilities  <span style=\"color:blue\"> (No need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pZA2DE1Zo2J",
    "outputId": "4897d390-485f-40ce-b464-583195b0968a"
   },
   "outputs": [],
   "source": [
    "ypred_prob[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.13 (mamba)",
   "language": "python",
   "name": "python313-mamba-module"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
